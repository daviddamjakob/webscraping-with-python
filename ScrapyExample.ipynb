{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Start with a command shell\n",
    "\n",
    "Install Scrapy\n",
    "\n",
    "```\n",
    "pip install scrapy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use another command shell and type \n",
    "\n",
    "```\n",
    "scrapy shell\n",
    "```\n",
    "\n",
    "to enter the scrapy shell\n",
    "\n",
    "Fetch a website\n",
    "\n",
    "```\n",
    "fetch(\"https://www.spiegel.de\")\n",
    "```\n",
    "\n",
    "View the response\n",
    "\n",
    "```\n",
    "print(response.text)\n",
    "```\n",
    "\n",
    "Access specific elements of the DOM tree using xpath\n",
    "\n",
    "```\n",
    "response.xpath(\"/html\").extract()\n",
    "\n",
    "response.xpath(\"//article/@aria-label\").extract()\n",
    "\n",
    "response.xpath(\"//div[@data-area='article_teaser'\").extract()\n",
    "\n",
    "response.xpath(\"//div[@data-area='article_teaser>news-l-compayt']\").extract()\n",
    "\n",
    "response.xpath(\"//div[@data-area='article_teaser>news-l-compayt']//span[@class='align-middle']/text()\").extract()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Write a spider for web crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the following script in Jupyter Notebook but it is better to run it on the command shell because jupyter keeps the process running and you have to restart the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class MySpider(scrapy.Spider):\n",
    "    name = \"MySpider\"\n",
    "    start_urls = [\n",
    "        'https://www.spiegel.de',\n",
    "    ]\n",
    "    \n",
    "    def parse(self, response):\n",
    "        for t in response.xpath(\"//article/@aria-label\").extract():\n",
    "            yield {'text': t}\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(MySpider)\n",
    "process.start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Crawl the webpage recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "text =[]\n",
    "authors =[]\n",
    "\n",
    "class MySpider(scrapy.Spider):\n",
    "    name = \"MySpider\"\n",
    "    start_urls = [\n",
    "        'https://www.spiegel.de',\n",
    "    ]\n",
    "    #Dangerous\n",
    "    def parse(self, response):\n",
    "        \n",
    "        \n",
    "        for t in response.xpath(\"//article/@aria-label\").extract():\n",
    "            text.append({'text': t})\n",
    "            yield {'text': t}\n",
    "        \n",
    "        author=response.xpath(\"//div[@class='font-sansUI lg:text-base md:text-base sm:text-s text-shade-dark mb-4']//a/text()\").extract()\n",
    "        if author!=None:\n",
    "            print(\"Author: \".join(author))\n",
    "            authors.append({'author': author})\n",
    "            yield {'author': author}\n",
    "            \n",
    "        next_page=response.xpath(\"//article//h2/a/@href\").extract()\n",
    "        for n in next_page:\n",
    "            yield scrapy.Request(response.urljoin(n),callback=self.parse)\n",
    "            \n",
    "            \n",
    "process = CrawlerProcess()\n",
    "process.crawl(MySpider)\n",
    "process.start()\n",
    "\n",
    "print(text)\n",
    "print(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
